{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.cross_validation as cv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "#Appropriate dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_clinical_eeg_data(datapath, sub):\n",
    "    # input arguments:\n",
    "    # datapath (string): path to the root directory\n",
    "    # sub (string): subject ID (e.g. chb01, chb02, etc)\n",
    "    \n",
    "    # output:\n",
    "    # eegdata (numpy array): samples x channels data matrix\n",
    "    # eegevents (pandas dataframe): labels and chunks\n",
    "    # channel_names (list): names of the channels\n",
    "    import pandas as pd\n",
    "    alldata = pd.read_csv(os.path.join(datapath, sub + '.csv')) #removed 'train' bc of how I saved\n",
    "    alldata.rename(columns={'Unnamed: 0': 'Index'})\n",
    "    eegevents = alldata[['labels', 'chunks']]\n",
    "    alldata.drop(['Unnamed: 0', 'labels', 'chunks'], axis=1, inplace=True)\n",
    "    names = alldata.keys()\n",
    "    return alldata.iloc[:].as_matrix(), eegevents, names\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isolate_label(labels_and_chunks):\n",
    "    labels_and_chunks=labels_and_chunks.as_matrix()\n",
    "    labels=labels_and_chunks[:,0]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make big dataset\n",
    "def build_big_dataset(path):\n",
    "    full_dataset=np.array([])\n",
    "    full_labels=np.array([])\n",
    "    #appending all the different subjects data together to make one giant dataset\n",
    "    \n",
    "    count=0; \n",
    "    for i in range(len(subjects)):\n",
    "        data, label_chunk, nodes = load_clinical_eeg_data(path,subjects[i])\n",
    "        label=isolate_label(label_chunk)\n",
    "        if(count==0):\n",
    "            full_dataset=data\n",
    "            full_labels=label\n",
    "        else:\n",
    "            np.concatenate((full_dataset,data))\n",
    "            np.concatenate((full_labels, label))\n",
    "        count=count+1\n",
    "        return full_dataset, full_labels\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take_max_every_64_points(x):\n",
    "    i=0; \n",
    "    max_array=[]\n",
    "    while(i<(x.shape[0])):\n",
    "        array=x[i:i+65]\n",
    "        max_array.append(np.max(array))\n",
    "        i+=64\n",
    "    max_array=np.array(max_array)\n",
    "    return max_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bandpass filter\n",
    "def apply_filters(x, order=4, fs=512.0, filt=None, btype='low', axis=0):\n",
    "    from scipy.signal import butter, filtfilt\n",
    "    nyq = .5 * fs\n",
    "    \n",
    "    if filt is None:\n",
    "        return x\n",
    "    if isinstance(filt, list):\n",
    "        f = [i/nyq for i in filt]\n",
    "        btype='band'\n",
    "    else:\n",
    "        f = filt/nyq\n",
    "        \n",
    "    b, a = butter(order, f, btype=btype, analog=False)\n",
    "    x = filtfilt(b, a, x, axis=axis)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def identification_log_reg(datapath):\n",
    "    #Get subject names from appropriate dir, -4 for .csv suffux\n",
    "    data,labels=build_big_dataset(datapath)\n",
    "    #Pass band filter on each node\n",
    "    data_filt=apply_filters(data, order=4, fs=64, filt=[12,32], btype='band')\n",
    "    #take max freq\n",
    "    dataset=np.apply_along_axis(take_max_every_64_points, 0,data_filt) \n",
    "    labels=np.apply_along_axis(take_max_every_64_points, 0,labels )\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #splitting into the different sets. This allows our professor to pass in our testing set, and if not itll create \n",
    "    #the testing set for us. \n",
    "    training_set, testing_set, training_labels, testing_labels =cv.train_test_split(dataset,labels)\n",
    "\n",
    "        \n",
    "\n",
    "    #train the data \n",
    "    model1 = LogisticRegression()\n",
    "    model1.fit(training_set,training_labels)\n",
    "    print \"Training accuracy:\" + str(model1.score(training_set,training_labels))\n",
    "\n",
    "    model1.score(testing_set, testing_labels)\n",
    "    print\"Testing accuracey\"+ str(model1.score(testing_set,testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:0.886061946903\n",
      "Testing accuracey0.891039823009\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/leilasolouki/Desktop/train\")\n",
    "path = os.getcwd()\n",
    "\n",
    "subjects = [f[:-4] for f in os.listdir(path)]\n",
    "identification_log_reg(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:0.957411504425\n",
      "Testing accuracey0.956305309735\n"
     ]
    }
   ],
   "source": [
    "subjects = subjects[:5]\n",
    "identification_log_reg(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
